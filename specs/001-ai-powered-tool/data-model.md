# Data Model: AI-Powered PR Summarizer

**Feature**: AI-Powered PR Summarizer  
**Phase**: 1 - Data Model Design  
**Date**: 2025-10-13

## Overview

This document defines the core data models and entities for the AI-powered PR summarizer system, focusing on data structures that support the six-section summary format and multi-source integration.

## Core Entities

### 1. Summary Request

**Purpose**: Represents a user-initiated request to generate a PR summary  
**Lifecycle**: Created → Processing → Completed/Failed  
**Storage**: Temporary (in-memory during processing)

```python
from enum import Enum
from datetime import datetime
from typing import Optional
from pydantic import BaseModel, HttpUrl, validator

class RequestStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing" 
    COMPLETED = "completed"
    FAILED = "failed"

class SummaryRequest(BaseModel):
    """User request to generate a PR summary"""
    request_id: str  # UUID for tracking
    github_pr_url: HttpUrl
    jira_ticket_id: str
    status: RequestStatus = RequestStatus.PENDING
    created_at: datetime
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None
    
    @validator('jira_ticket_id')
    def validate_jira_id(cls, v):
        # Validate format: PROJECT-123
        import re
        if not re.match(r'^[A-Z]+\-\d+$', v):
            raise ValueError('Jira ticket ID must be in format PROJECT-123')
        return v
    
    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }
```

### 2. Integration Context

**Purpose**: Aggregates data from all external sources before LLM processing  
**Lifecycle**: Built during data gathering phase, consumed by LLM service  
**Storage**: Temporary (discarded after summary generation)

```python
from typing import List, Dict, Optional, Any
from pydantic import BaseModel

class GitHubData(BaseModel):
    """GitHub PR information"""
    pr_number: int
    title: str
    description: str
    author: str
    reviewers: List[str]
    files_changed: List[str]
    additions: int
    deletions: int
    commit_messages: List[str]
    linked_issues: List[str]
    
class JiraData(BaseModel):
    """Jira ticket information"""
    ticket_key: str
    summary: str
    description: str
    issue_type: str
    priority: str
    status: str
    assignee: Optional[str]
    reporter: str
    acceptance_criteria: Optional[str]
    linked_tickets: List[str]
    epic_key: Optional[str]
    sprint: Optional[str]
    
class ConfluenceData(BaseModel):
    """Confluence documentation"""
    pages_found: List[Dict[str, Any]]  # page_id, title, content_excerpt
    search_terms_used: List[str]
    total_pages: int
    
class GoogleDocsData(BaseModel):
    """Google Docs information"""
    documents_found: List[Dict[str, Any]]  # doc_id, title, content_excerpt
    search_terms_used: List[str]
    total_documents: int

class IntegrationContext(BaseModel):
    """Aggregated context from all sources"""
    request_id: str
    github_data: Optional[GitHubData] = None
    jira_data: Optional[JiraData] = None
    confluence_data: Optional[ConfluenceData] = None
    google_docs_data: Optional[GoogleDocsData] = None
    gathering_errors: List[str] = []  # Non-fatal errors during data collection
    total_sources: int = 0
    successful_sources: int = 0
    
    def add_error(self, source: str, error: str):
        """Add a non-fatal error during data gathering"""
        self.gathering_errors.append(f"{source}: {error}")
    
    def calculate_success_rate(self) -> float:
        """Calculate percentage of successful source integrations"""
        if self.total_sources == 0:
            return 0.0
        return (self.successful_sources / self.total_sources) * 100
```

### 3. PR Summary

**Purpose**: Contains the structured six-section summary output  
**Lifecycle**: Generated by LLM, returned to user, optionally logged  
**Storage**: Temporary (returned in API response, not persisted)

```python
from typing import Dict, List
from pydantic import BaseModel, validator

class SummarySection(BaseModel):
    """Individual section of the summary"""
    title: str
    content: str
    word_count: int
    
    @validator('content')
    def validate_content_length(cls, v):
        # Ensure reasonable content length (50-200 words per section)
        word_count = len(v.split())
        if word_count < 10:
            raise ValueError('Section content too short (minimum 10 words)')
        if word_count > 300:
            raise ValueError('Section content too long (maximum 300 words)')
        return v

class PRSummary(BaseModel):
    """Complete structured PR summary"""
    request_id: str
    github_pr_url: str
    jira_ticket_id: str
    
    # Six required sections
    business_context: SummarySection
    code_change_summary: SummarySection  
    business_code_impact: SummarySection
    suggested_test_cases: SummarySection
    risk_complexity: SummarySection
    reviewer_guidance: SummarySection
    
    # Metadata
    total_word_count: int
    sources_used: List[str]  # Which services provided data
    generation_time_seconds: float
    model_confidence: Optional[float] = None  # If provided by LLM
    generated_at: datetime
    
    @validator('total_word_count')
    def calculate_total_words(cls, v, values):
        """Auto-calculate total word count from sections"""
        sections = [
            values.get('business_context'),
            values.get('code_change_summary'),
            values.get('business_code_impact'),
            values.get('suggested_test_cases'),
            values.get('risk_complexity'),
            values.get('reviewer_guidance')
        ]
        total = sum(section.word_count for section in sections if section)
        return total
    
    def to_formatted_text(self) -> str:
        """Convert summary to formatted text for display"""
        sections = [
            ("Business Context", self.business_context.content),
            ("Code Change Summary", self.code_change_summary.content),
            ("Business/Code Impact", self.business_code_impact.content),
            ("Suggested Test Cases", self.suggested_test_cases.content),
            ("Risk & Complexity", self.risk_complexity.content),
            ("Reviewer Guidance", self.reviewer_guidance.content)
        ]
        
        formatted = []
        for title, content in sections:
            formatted.append(f"## {title}\n\n{content}\n")
        
        return "\n".join(formatted)
```

### 4. External Service Connection

**Purpose**: Configuration and authentication details for external services  
**Lifecycle**: Loaded at application startup, used throughout service lifetime  
**Storage**: Environment variables and configuration files

```python
from typing import Optional
from pydantic import BaseSettings, validator

class GitHubConfig(BaseModel):
    """GitHub API configuration"""
    api_token: str
    base_url: str = "https://api.github.com"
    timeout_seconds: int = 8
    max_retries: int = 3
    
class JiraConfig(BaseModel):
    """Jira API configuration"""
    server_url: str  # https://company.atlassian.net
    username: str
    api_token: str
    timeout_seconds: int = 8
    max_retries: int = 3
    
class ConfluenceConfig(BaseModel):
    """Confluence API configuration"""
    server_url: str  # https://company.atlassian.net/wiki
    api_token: str
    timeout_seconds: int = 10
    max_search_results: int = 5
    
class GoogleConfig(BaseModel):
    """Google services configuration"""
    credentials_file_path: str
    drive_search_timeout: int = 10
    docs_extraction_timeout: int = 8
    max_documents: int = 3
    
class GeminiConfig(BaseModel):
    """Google Gemini LLM configuration"""
    api_key: str
    model_name: str = "gemini-2.5-pro"
    max_tokens: int = 1000  # For response
    temperature: float = 0.3  # Lower for more consistent output
    timeout_seconds: int = 15

class ServiceConnections(BaseSettings):
    """Complete external service configuration"""
    github: GitHubConfig
    jira: JiraConfig
    confluence: ConfluenceConfig
    google: GoogleConfig
    gemini: GeminiConfig
    
    # Global settings
    max_concurrent_requests: int = 10
    request_timeout_total: int = 30
    
    class Config:
        env_file = ".env"
        env_nested_delimiter = "__"  # Allows GITHUB__API_TOKEN format
```

## Supporting Models

### 5. Error Models

**Purpose**: Structured error handling and user feedback

```python
from enum import Enum
from typing import Optional, Dict, Any

class ErrorCode(str, Enum):
    INVALID_INPUT = "invalid_input"
    SERVICE_UNAVAILABLE = "service_unavailable"
    AUTHENTICATION_FAILED = "authentication_failed"
    RATE_LIMIT_EXCEEDED = "rate_limit_exceeded"
    PROCESSING_TIMEOUT = "processing_timeout"
    LLM_GENERATION_FAILED = "llm_generation_failed"
    UNKNOWN_ERROR = "unknown_error"

class ServiceError(BaseModel):
    """Error from external service integration"""
    service_name: str  # "github", "jira", "confluence", etc.
    error_code: ErrorCode
    error_message: str
    is_recoverable: bool
    retry_after_seconds: Optional[int] = None

class APIError(BaseModel):
    """Standardized API error response"""
    error_code: ErrorCode
    message: str  # User-friendly message
    details: Optional[Dict[str, Any]] = None
    request_id: Optional[str] = None
    timestamp: datetime
    
    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }
```

### 6. API Response Models

**Purpose**: Standardized API response formats

```python
from typing import Generic, TypeVar, Optional
from pydantic import BaseModel
from pydantic.generics import GenericModel

T = TypeVar('T')

class APIResponse(GenericModel, Generic[T]):
    """Standardized API response wrapper"""
    success: bool
    data: Optional[T] = None
    error: Optional[APIError] = None
    request_id: str
    processing_time_ms: int
    
class SummaryResponse(APIResponse[PRSummary]):
    """Specific response for summary generation"""
    sources_attempted: int
    sources_successful: int
    partial_failure: bool = False  # True if some sources failed
    
class HealthResponse(BaseModel):
    """Health check response"""
    status: str  # "healthy", "degraded", "unhealthy"
    services: Dict[str, str]  # service_name -> status
    timestamp: datetime
    uptime_seconds: int
```

## Validation Rules

### Input Validation

1. **GitHub PR URLs**: Must match pattern `https://github.com/owner/repo/pull/number`
2. **Jira Ticket IDs**: Must match pattern `PROJECT-123` (uppercase letters, hyphen, numbers)
3. **Content Limits**: 
   - PR description: max 10,000 characters
   - Jira description: max 50,000 characters
   - Document excerpts: max 5,000 characters each

### Business Rules

1. **Summary Generation**:
   - Minimum 2 successful source integrations required
   - Each section must be 50-300 words
   - Total summary must be 200-1500 words

2. **Data Freshness**:
   - GitHub data: real-time (no caching)
   - Jira data: real-time (no caching)
   - Document data: acceptable if accessed within processing window

3. **Error Handling**:
   - Service failures logged but don't block processing
   - Authentication errors require user notification
   - Rate limiting triggers exponential backoff

## Relationships

```
SummaryRequest (1) -> (1) IntegrationContext
IntegrationContext (1) -> (1) PRSummary
SummaryRequest (1) -> (0..1) PRSummary
ServiceConnections (1) -> (N) Service Integrations
```

## Performance Considerations

1. **Memory Usage**:
   - IntegrationContext: ~50KB typical, 500KB maximum
   - PRSummary: ~5KB typical
   - Total per request: <1MB

2. **Processing Time**:
   - Data gathering: 5-10 seconds (parallel)
   - LLM generation: 3-8 seconds
   - Total: <30 seconds target

3. **Concurrent Requests**:
   - Models designed for stateless processing
   - No shared mutable state between requests
   - Memory cleanup after request completion

This data model supports the constitutional requirements for type safety, testability, and performance while enabling the six-section summary format specified in the requirements.